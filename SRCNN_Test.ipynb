{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Mg4kofp5G0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgp_5yYyqbAk"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MclmlZTzW7T"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CemI-uhzeJt"
      },
      "outputs": [],
      "source": [
        "def preprocess(example):\n",
        "    # LR = low-res image (input), HR = high-res image (label)\n",
        "    lr = tf.image.convert_image_dtype(example['lr'], tf.float32)\n",
        "    hr = tf.image.convert_image_dtype(example['hr'], tf.float32)\n",
        "\n",
        "    # Upscale the LR image to match HR size (x4 for DIV2K)\n",
        "    lr_upscaled = tf.image.resize(lr, size=tf.shape(hr)[:2], method='bicubic')\n",
        "\n",
        "    return lr_upscaled, hr\n",
        "\n",
        "# Load pre-defined splits directly\n",
        "train_data = tfds.load('div2k/bicubic_x4', split='train', shuffle_files=True)\n",
        "val_data = tfds.load('div2k/bicubic_x4', split='validation', shuffle_files=True)\n",
        "\n",
        "# Apply preprocessing\n",
        "train_data = train_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_data = val_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Prepare batches\n",
        "BATCH_SIZE = 1\n",
        "train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_data = val_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DBqRvtdqrCW"
      },
      "source": [
        "\n",
        "# Creating The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL2eMZqtc8lv"
      },
      "outputs": [],
      "source": [
        "def SRCNN():\n",
        "    model = Sequential()\n",
        "    # Patch extraction and representation\n",
        "    model.add(Conv2D(64, (9, 9), activation='relu', padding='same', input_shape=(None, None, 3)))\n",
        "    # Non-linear mapping\n",
        "    model.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
        "    # Reconstruction\n",
        "    model.add(Conv2D(3, (5, 5), activation='linear', padding='same'))\n",
        "    return model\n",
        "\n",
        "srcnn = SRCNN()\n",
        "srcnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neJCwYcwdq6v"
      },
      "source": [
        "# Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aZfQtTkdz7D"
      },
      "outputs": [],
      "source": [
        "srcnn.fit(train_data, validation_data=val_data, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS7AiiI4HBl6"
      },
      "source": [
        "# Test Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmqPcI-JHF7J"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(path, upscale_size=None):\n",
        "    # Load image\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "\n",
        "    # Resize (optional, if not already the upscaled size)\n",
        "    if upscale_size:\n",
        "        img = tf.image.resize(img, upscale_size, method='bicubic')\n",
        "\n",
        "    # Convert to float32 and normalize\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    # Add batch dimension\n",
        "    img = tf.expand_dims(img, axis=0)  # shape: (1, h, w, 3)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Load the low-res upscaled image\n",
        "input_img = load_and_preprocess_image(\"willy_14.png\")\n",
        "\n",
        "# Predict high-res version using SRCNN\n",
        "output = srcnn.predict(input_img)\n",
        "\n",
        "# Remove batch dimension for visualization\n",
        "output_img = tf.squeeze(output, axis=0)\n",
        "\n",
        "# Show original (input) and super-resolved (output) side by side\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Input (Bicubic Upscaled)\")\n",
        "plt.imshow(tf.squeeze(input_img))\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"SRCNN Output\")\n",
        "plt.imshow(output_img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Cgp_5yYyqbAk"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
